# El Nino Analysis using SparkCluster

## Overview
This repository contains code for a Big Data Analytics project leveraging Apache Spark. With Docker, you can easily set up a Spark cluster and run your application without needing to manually configure Spark.

## Prerequisites

- **Docker**: Make sure Docker is installed on your system. You can download it from the [Docker website](https://www.docker.com/get-started).
- **Docker Compose**: Docker Compose is used to define and run multi-container applications. It is included in Docker Desktop for Windows and macOS.

## Installation Instructions

### 1. Clone the Repository

Clone this repository to your local machine using Git:

```bash
git clone https://github.com/yourusername/Big_Data_Analytics.git
cd Big_Data_Analytics'''

### 2. Build and Start the Docker Containers
'''docker-compose up --build'''

### 3. Monitor the Spark Cluster
'''http://localhost:8080'''

### 4. Stop the Containers
'''docker-compose down'''

